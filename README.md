Deepfake Video Detection for Frontal Faces
Project Overview
This project focuses on developing a robust system for detecting deepfake videos, specifically targeting frontal faces. With the rising sophistication of deepfake technology, there is an increasing need for reliable methods to identify manipulated content. This project aims to contribute to the field by providing an efficient and accurate deepfake detection model.

Features
Frontal Face Detection: Specializes in detecting deepfakes in videos where subjects face the camera directly, ensuring high accuracy for frontal face scenarios.
Advanced Machine Learning Models: Utilizes state-of-the-art machine learning and deep learning techniques to distinguish between genuine and manipulated videos.
Dataset and Training: Trained on a diverse dataset comprising authentic and deepfake videos to ensure the model generalizes well across different scenarios.
Performance Metrics: Evaluates the model using standard performance metrics such as accuracy, precision, recall, and F1-score to validate its effectiveness.
User-Friendly Interface: Provides a simple interface for users to upload videos and get real-time detection results.
Technologies Used
Python: Core programming language for developing the detection algorithms.
OpenCV: Used for image and video processing tasks.
TensorFlow/Keras: Frameworks for building and training deep learning models.
Dlib: For face detection and landmark localization.
NumPy & Pandas: For data manipulation and analysis.
